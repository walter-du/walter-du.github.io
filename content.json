[{"title":"Tiny and Overlapping Fragment Attacks","date":"2017-02-08T16:00:00.000Z","path":"2017/02/09/Tiny_and_overlapping_fragment_attack/","text":"http://blog.csdn.net/dog250/article/details/6572779其中提到的 “两类ip fragment 的攻击”: “TCP小包攻击” 和 “TCP重叠攻击”个人理解是这两种 attacks 成功的前提是 防火墙不重组 ip fragment, filter 默认会 pass 除第一个 fragment 的所有其它 ip fragment ;去翻了下 协议栈 源码，Linux 在 priority 很高的 hook ‘ipv4_conntrack_defrag’ 就会重组 ip fragment ，故应该不会存在; “TCP小包攻击”: 防火墙通常会 check 第一个 ip fragment 的信息，但第一个 fragment 过小，其四层信息不完整(eg: TCP 的 Flags)，filter 就可能匹配不上导致 pass ; “TCP重叠攻击”: TCP 的重组算法，如果两个 ip fragment 在 reassembly 时有 overlap，其中一个 fragment 会 overwrite 另一个的 overlap 部分 ; 问题就来了，如果第二 fragment 有问题且被 filter pass，那么接收端在重组时就可能用有问题的部分 overwrite 第一个 fragment 的 overlap 部分 ; 一个典型的例子就是 tcp syn 问题: ‘The filter is configured to drop TCP connection request packets’； 第一个正常 fragment SYN=0, ACK=1，非 syn， pass 第二个问题 fragment SYN=1, ACK=0，也会 sneak and pass 接收端就会重组成一个新的 TCP connection request , that&apos;s it. 另外，提到的 “nf-HiPAC” , 内核配置项 “IP_NF_HIPAC” 可开启。 12345678910111213141516171819202122config IP_NF_HIPAC tristate &apos;nf-HiPAC support (High Performance Packet Classification)&apos; depends on IP_NF_IPTABLES help nf-HiPAC is a high performance packet classification framework on top of netfilter. It is based on a novel classification algorithm that is very much superior to the linear classication algorithm implemented by iptables. It provides highly efficient packet matching which is especially useful when large rulesets and/or high bandwidth networks are involved. Ruleset updates are submitted dynamically to the kernel via netlink on a per rule basis. In addition to its native matches (e.g. ip, proto, port match) nf-HiPAC allows the usage of iptables matches and targets and thus provides the same flexibility as iptables. Furthermore the semantics and construction of a ruleset is identical to the iptables way so that the internal representation is completely transparent to the user. Basically, you can think of nf-HiPAC as an alternative, optimized iptables filter table. Note that it cannot be used for packet mangling or NAT but you can still adopt iptables&apos; mangle or nat table for that purpose since nf-HiPAC and iptables can be used together at the same time. http://blog.csdn.net/dog250/article/details/7269212之前关于 broute 和 REDIRECT 的一些疑问; http://blog.csdn.net/dog250/article/details/6612496值得阅读 PS: 致敬原作者","tags":[{"name":"network","slug":"network","permalink":"http://walter-du.github.io/tags/network/"},{"name":"Linux","slug":"Linux","permalink":"http://walter-du.github.io/tags/Linux/"}]},{"title":"Route and conntrack","date":"2017-02-05T16:00:00.000Z","path":"2017/02/06/Route_AND_conntrack/","text":"两者关系不明显；路由表和连接跟踪表对应着不同的功能； 路由表用于确定 skb 的 ip_output，连接跟踪表记录了 skb 源和目的两端的五元组信息； 即有了路由表，包才知道往哪里发送，包发送后才知道并记录该包完整的源和目的五元组，即创建连接跟踪表； CAUTION: iptable nat table 规则如其名，Network Address Translation 就是用于改变包的五元组信息的，即影响连接跟踪表的创建。 但是，一旦某条连接跟踪表创建后，那么在其老化前，无论 iptable nat table 上的规则如何变化，都不会影响对应的包根据该条连接跟踪表来进行两端的发收。 Why? 修改 nat table 后为何不实时刷新 conntrack table ，refer to ‘ip_nat_fn’，显然不很容易；Linux 可能认为也无大必要。 实在要为之，或者可以在创建连接跟踪表时 private point 影响其五元组的 nat table rules，然后联动，may be it works, no guarantee ~","tags":[{"name":"network","slug":"network","permalink":"http://walter-du.github.io/tags/network/"},{"name":"Linux","slug":"Linux","permalink":"http://walter-du.github.io/tags/Linux/"}]},{"title":"Git manual","date":"2017-01-22T16:00:00.000Z","path":"2017/01/23/Git_manual/","text":"常用操作$ git branch -vv[l/a] 查看branch[本地/与origin分支] $ git push origin master 提交本地修改 $ git checkout release 切换到本地 release 分支 $ git pull origin release 更新本地库中的 origin/release 分支且合并到本地 release 分支 $ git log --graph --pretty=oneline --abbrev-commit 查看日志 基本概念Git 分为 工作区 (Working Directory) 、暂存区 (Stage) 和 版本库 (Repository) Git 管理的是修改，NOT 文件; Git 在远端和本地各维护着一个代码库; 初始化Git仓库 和 添加\\提交文件初始化一个Git仓库，使用 git init 命令。 添加文件到Git仓库，分两步： 第一步，使用命令 git add ，注意，可反复多次使用，添加多个文件； 第二步，使用命令 git commit ，完成。 查看状态 git status 和 git diff要随时掌握工作区的状态，使用 git status 命令。 如果 git status 告诉你有文件被修改过，用 git diff [--staged] 可以查看修改内容。 版本回退 git resetHEAD指向的版本就是当前版本，因此，Git允许我们在版本的历史之间穿梭，使用命令 git reset --hard commit_id 。 穿梭前，用 git log 可以查看提交历史，以便确定要回退到哪个版本。 要重返未来，用 git reflog 查看命令历史，以便确定要回到未来的哪个版本。 查看日志日志简写 git log --pretty=oneline --abbrev-commit 日志跟踪 git log --graph --pretty=oneline --abbrev-commit 撤销修改场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令 git checkout -- file。 场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步: 第一步用命令 git reset HEAD file，就回到了场景1; 第二步按场景1操作。 场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，参考版本回退一节，不过前提是没有推送到远程库。 git checkoutgit checkout -- readme.txt 意思就是，把 readme.txt 文件在工作区的修改全部撤销，这有两种情况： 一种是 readme.txt 自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态; 一种是 readme.txt 已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。 总之，就是让这个文件回到最近一次 git commit 或 git add 时的状态。 $ git checkout -- readme.txt git resetgit reset HEAD file 可以把暂存区的修改撤销掉（unstage），重新放回工作区： $ git reset HEAD readme.txt Unstaged changes after reset: M readme.txt git reset命令既可以回退版本，也可以把暂存区的修改回退到工作区。 删除文件$ rm test.txt $ git rm test.txt $ git commit -m &quot;remove test.txt&quot; git rm 用于删除一个文件。如果这个文件已经被提交到版本库，那么你永远不用担心误删， 但是要小心，你只能恢复文件到最新版本，你会丢失最近一次提交后你修改的内容。 首次关联和推送$ git remote add origin https://github.com/&lt;git_name&gt;/&lt;git_repos_name&gt;.git [ OR $ git remote add origin git@github.com:&lt;git_name&gt;/&lt;git_repos_name&gt;.git ] $ git push -u origin master PS: Git支持多种协议，包括https，但通过ssh支持的原生git协议速度最快。 switch to git : $ git remote rm origin $ git remote add origin git@github.com:&lt;git_name&gt;/&lt;git_repos_name&gt;.git 提交From now on, 只要本地作了提交，就可以通过命令： $ git push origin master Branch 管理创建并切换到分支 $ git checkout -b dev == $ git branch dev $ git checkout dev 查看分支 $ git branch $ git branch -r $ git branch -a $ git branch -vv 切换到 master 分支 $ git checkout master 合并 dev 分支修改到 当前 分支 $ git merge dev 删除 dev 分支 $ git branch -d dev Branch 更新$ git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt; 取回 origin 主机的 next 分支，与本地的 master 分支合并: $ git pull origin next:master 如果远程分支是与当前分支合并，则冒号后面的部分可以省略: $ git pull origin next == $ git fetch origin $ git merge origin/next $ git pull origin master == $ git fetch origin master 从远程的 origin 的 master 主分支下载最新的版本到 origin/master 分支上 $ git log -p master..origin/master 比较本地的 master 分支和 origin/master 分支的差别 $ git merge origin/master 合并到当前分支 == $ git fetch origin master:tmp $ git diff tmp $ git merge tmp 更新某个文件 $ git fetch origin card [update本地库中的 origin/card 分支] $ git checkout origin/card -- &lt;path/to/file&gt; [获取本地库中的 origin/card 分支的某个文件到本地 card 分支] Tag 管理在最新 commit 上打 tag $ git tag v1.0 在某个 commit id 上打 tag $ git tag v0.5 &lt;commit_id&gt; $ git tag -a v0.5 [-m &lt;msg&gt;] &lt;commit_id&gt; 查看 tag $ git tag $ git show &lt;tag_name&gt; 删除某个 tag $ git tag -d &lt;tag_name&gt; 推送某个 tag 到 remote $ git push origin v1.0","tags":[{"name":"git","slug":"git","permalink":"http://walter-du.github.io/tags/git/"}]},{"title":"UDP Q&A","date":"2017-01-21T16:00:00.000Z","path":"2017/01/22/UDP_Q&A/","text":"UDP 发送大包会发生什么? UDP 不存在发送缓冲区; 套接口选项 ‘SO_SNDBUF’ 可用来设置允许 write 的 UDP 数据报大小的上限,超出则返回 EMSGSIZE ; UDP 层传到 IP 层,IP 层传到链路层时,如果大于 MTU 则会导致分片; UDP write 若能成功返回,则说明 UDP 数据报(或其分片片段)一路向下,已加入到链路层队列。 UDP 发包过快会发生什么？对端会如何处理？ 对于发送端,发送过快,发送端的 NIC 的 DMA ring 来不及消耗(从 NIC 发出), DMA ring 用完,通常会 stop 发送软中断,即停止链路层的输出队列 skb 出队,进而输出队列满,返回 ENOBUFS; 对于接收端,接收过快(NIC 能力范围内),导致 UDP 的接收缓冲区满(应用进程未及时读),则 UDP 直接将收到的数据报丢弃; 对于接收端,若实在太快导致 NIC 的接收中断 overflow error, NIC 已无力回天,显然报文就会默默的消失。 UDP 是否需要绑定源端口? 可以 bind,但不是必须的; 未 bind 直接 sendto 的话, UDP 会自动选择一个 PORT 然后将其置为绑定状态。 UDP 为何是无连接的(connectionless)？ 发送端和接收端不必存在长期的关系。 UDP 何为有边界记录？ 每个 UDP 数据报都有一个长度,其长度值会直接传给接收端。 UDP 数据报一次 read 未读完,是否还能继续读完？ 每个 UDP 数据报都有一个长度,通常应用进程 write 时应保证这个长度小于 MTU 以避免分片; 应用进程 read UDP 数据报时,应尽可能一次读完一整个 UDP 数据报; 即 readmsg 中设置的 buf’s nbytes &gt;= sizeof (UDP 数据报); 因为每个 UDP 数据报是以一个整体 skb 出队的,一次 read 不完的话这个 skb 中剩余的 data 会被丢弃,并且会返回 msg-&gt;msg_flags |= MSG_TRUNC; 12345copied = skb-&gt;len - sizeof(struct udphdr);if (copied &gt; len) &#123; copied = len; msg-&gt;msg_flags |= MSG_TRUNC;&#125; 如果 readmsg 中 flags 设置了 MSG_TRUNC,则不管 readmsg 实际读取了多少 nbytes,其返回值总是为整个 UDP 数据报的长度: 12if (flags &amp; MSG_TRUNC) err = skb-&gt;len - sizeof(struct udphdr); PS: Refer to ‘udp.c‘ – ‘udp_recvmsg()‘. UDP 为何不可靠？ 数据报出错(丢失,参见上)后无重传机制。 UDP 适用什么场景？ 广播或多播; 少量的数据传输,简答的请求-应答交互; 尽量可靠的网络,如局域网。 UDP 与 “两军问题” ？ BAIDU 或 GOOGLE UDP 与 ‘SO_REUSEADDR’ 和 ‘SO_REUSEPORT’ UDP 允许完全重复的绑定: 同 IP 和 同端口绑定到多个套接字; TCP 则不完全支持。 PS: Refer to “UNIX Network Programming VOLUME 1” Page 179. SS 是否支持封装(encapsulate) UDP 报文? Socks4 不支持, Socks5 支持 UDP;","tags":[{"name":"network","slug":"network","permalink":"http://walter-du.github.io/tags/network/"}]},{"title":"Ssh-tunnel and SS","date":"2017-01-21T16:00:00.000Z","path":"2017/01/22/Ssh-tunnel_AND_SS/","text":"On-Top update ‘hosts’ update ‘g~f~wlist’ Tools Windows 自带 MD5 命令: certutil -hashfile MD5 ; ‘ssh’/‘netcat’(nc,支持明文或其他加密) 都能实现简单的端口转发功能; eg: 查看某 server 是否开启 80 端口: # nc &lt;server’s ip&gt; 80 (strace 或 tcpdump 查看报文交互) ‘dig’ for lookup ; 单一的 ssh-tunnel 由于 ssh 本身就是基于 RSA 加密技术,所以 G~F~W 无法从数据传输的过程中对加密数据内容进行关键词分析,避免了被重置链接的问题; 但由于创建隧道和数据传输的过程中, ssh 本身的特征是明显的,所以 G~F~W 可以通过分析连接的特征进行干扰,导致 ssh 存在被定向进行干扰的问题。 SS 简单理解的话, SS 是将原来 ssh 创建的 Socks5 协议拆开成 server 端和 client 端,其原理基本上和利用 ssh-tunnel 大致类似: 1.客户端发出的请求基于 Socks5 协议跟 ss-local 端进行通讯,由于这个 ss-local 一般是本机或路由器或局域网的其他机器,不经过 G~F~W ,所以解决了上面被 G~F~W 通过特征分析进行干扰的问题; 2.ss-local 和 ss-server 两端通过多种可选的加密方法进行通讯,经过 G~F~W 的时候是常规的 TCP 包,没有明显的特征码且 G~F~W 也无法对通讯数据进行解密; 3.ss-server 将收到的加密数据进行解密,还原原来的请求,再发送到用户需要访问的服务,获取响应原路返回。 两条 DNS 查询链： 国外：Client—ChinaDNS—dnsmasq—SS—代理Server—GoogleDNS国内：Client—ChinaDNS—114DNS","tags":[{"name":"network","slug":"network","permalink":"http://walter-du.github.io/tags/network/"},{"name":"SS","slug":"SS","permalink":"http://walter-du.github.io/tags/SS/"}]},{"title":"'Staticmethod' and 'classmethod'","date":"2017-01-17T16:00:00.000Z","path":"2017/01/18/Staticmethod_AND_classmethod/","text":"classmethod 的存在是显然的； staticmethod 的意义在哪里?主要还是作用域吧，如果某个函数只在某个 class 中使用，且无关 self or cls ，则可以一用，比散落在外面强；其实直接 self 不用也无妨；只是意义更明确，此为 class’s function 。 12345if NOT access instance &apos;self&apos;: if NOT access class &apos;cls&apos;: choose &apos;staticmethod&apos; else: choose &apos;classmethod&apos; Refer to: http://pythoncentral.io/difference-between-staticmethod-and-classmethod-in-python/ http://stackoverflow.com/questions/12179271/python-classmethod-and-staticmethod-for-beginner","tags":[{"name":"Python","slug":"Python","permalink":"http://walter-du.github.io/tags/Python/"}]},{"title":"Process schedule","date":"2016-12-17T16:00:00.000Z","path":"2016/12/18/Process_scheduling/","text":"进程调度时机 显示调度,进程主动调度或由于缺少相应申请的资源,显示调用调度器让出CPU； 隐式调度,整个linux系统在运行过程中非显示的调用调度器,这又分两种情况： A)非抢占调度 比如:在系统调用,中断处理,异常处理返回用户态时,该进程的时间片已经用完 B)抢占调度 比如:当前内核态执行过程中事先没有禁止内核态抢占,有中断产生并且中断处理又产生了更高优先级进程,那么就会直接抢占前面的内核态执行体 内核态抢占的抢占点有两处:A)中断处理返回内核态时(如果事先没有禁止内核态抢占[preempt_disable])B)重新起用内核态抢占时([preempt_enable]) 相关数据结构:12345678struct thread_info&#123; ..... int preempt_count; /* 0 =&gt; preemptable, &lt;0 =&gt; BUG */ (PREEMPT 0-7位表示内核态禁止抢占计数器,只要PREEMPT为0时才允许内核态抢占； SOFTIRQ 8-15表示本地软中断禁止计数器,HARDIRQ 16-27表示本地CPU硬中断嵌套的深度) .....&#125; 常见的调度点1)进程被阻塞时 比如申请资源时被阻塞; 2)调整参数时 比如通过 sched_setscheduler() ,nice()等函数调整进程的调度策略,静态优先级时; 3)睡眠进程被唤醒时 比如 wake_up 唤醒等待队列中的进程时,如果该进程具有更高优先级则会设置当前进程 TIF_NEED_RESCHED ,如果允许内核态抢占,则会发生调度; 4)中断返回时 如果中断处理过程中设置了 TIF_NEED_SCHED 标志,中断返回时: 当返回到用户态,就会检查都会 TIF_NEED_SCHED 标志; 当返回到内核态,如果抢占被使能,也会检查 TIF_NEED_SCHED 标志。 5)异常,系统调用返回时 6)执行了preempt_enable()函数 应用态和内核态的while(1)通过系统调用后进入内核态后，while(1)，此时用户程序停止但是可以从外ping通网络,为什么？和在应用层while(1)有什么区别？ 对于UP来讲，进入内核态后while(1)，由于中断仍打开，此时所有的中断都能够正常进行，中断返回时：1234567891011/* * Exit an interrupt context. Process softirqs if needed and possible: */void irq_exit(void)&#123; account_system_vtime(current); sub_preempt_count(IRQ_EXIT_OFFSET);/* 自减硬中断计数 */ if (!in_interrupt() &amp;&amp; local_softirq_pending()) invoke_softirq();/* 执行挂起的软中断 */ preempt_enable_no_resched();&#125; 如果有软中断被激活，则会唤醒软中断并执行，故网络接收/发送软中断都有机会得到执行，所以可以从外ping通网络。由于中断发生在内核态并且禁止了内核抢占，从中断返回时直接恢复到内核态继续while(1)，而不会检查 need_resched ，故不会有调度产生，其他进程（包括用户进程和内核线程）都不会有机会执行，事实上此时系统已不可能完成任何实际功能了。 对于用户态的while(1)，每次时钟中断程序都会检查进程的时间片，当进程用完其时间片时，该进程会设置 need_resched ，待到从中断返回时，恢复到用户态时会检查 need_resched ，所以此时就会被调度。至于每次top看到此进程占用CPU 99%，CPU利用率100%，这依赖于top程序的统计方法，由于while(1)几乎每次都会用完了自己的时间片才被调度，从不主动放弃CPU，即任何时候都至少有这个进程处于 TASK_RUNNING 状态，调度程序从不会选择idle进程（进程0），故CPU得利用率总是100%。","tags":[{"name":"Linux","slug":"Linux","permalink":"http://walter-du.github.io/tags/Linux/"}]},{"title":"Libevent and event-driven model","date":"2016-12-15T16:00:00.000Z","path":"2016/12/16/Libevent_AND_event-driven_model/","text":"基于 event 驱动的 I/O 模型 (Libevent, GDBus) 的关注点 对不同的 event(fd) 设置不同的超时时间; 对不同的 event(fd) 设置不同的优先级; 运行过程中动态的 增加/删除 需关注的 event(fd); Libevent (Reactor) ‘select_dispatch’ 中 ‘random() % nfds;’: 相同优先级的 event 有公平的处理机会(入队先后顺序); ‘event_process_active’,’activequeues’: 不同优先级的 event 加入到不同的 active 队列; ‘event_process_active’: 一次 loop 虽然将所有可用的 event 都入 active 队列，但是只处理最高优先级 active 队列中的 event ; ‘EVLIST_INSERTED’ 用以动态的 add/del event; 支持多线程: 1: ‘event_process_active_single_queue’ 中调用 event 处理函数 ‘ev_callback’ 时释放了 LOCK ; 2: 主要的非临界区: select/epoll 时 和 调用 event 处理函数 ‘ev_callback’ 时(显然此处理函数不应操作公共变量); 3: ‘event_continue’: 线程 A 在处理某个优先级队列中的 event, 线程 B 发现了更高优先级的 event ,则线程 A 完成当前 event 的处理后，停止处理当前队列中的下一个 event , 进而进入下一次 loop 去处理更高优先级的 event 。","tags":[{"name":"I/O","slug":"I-O","permalink":"http://walter-du.github.io/tags/I-O/"},{"name":"IPC","slug":"IPC","permalink":"http://walter-du.github.io/tags/IPC/"}]},{"title":"Why 'epoll' faster than 'select'","date":"2016-12-13T16:00:00.000Z","path":"2016/12/14/Epoll_AND_select/","text":"epoll 快于 select 的本质是有 kernel 时刻在帮忙。select() 需要进程当场轮询所有的 fd (调用每个 fd 对应的底层 poll)以确定可用的 fd 集;而 epoll epoll_wait() 是进程直接返回被内核 I/O 事件异步唤醒而加入到 ready list 的 fd 集，相当于其收集可用的 fd 集的工作已由内核(软中断)在之前就完成了。 select 的实现select 比较常用，其实现过程大致如下:sys_select -&gt; do_select{ 将所有的 fd 从用户态 copy 到内核态; 依次调用每个 fd 对应的底层 poll 函数，对于 socket fd 通常就是 tcp_poll/udp_poll(datagram_poll)， check 对应的 sk queue 是否有数据可读/可写，若有则保存到临时变量; 每调用一次底层 poll 函数，还会 cond_resched() 一次 (2.6.15); 所有 fd 都 poll 一遍以后，若有数据则返回; 没有则 check 是否 timeout，没有则 sleep timeout，睡眠结束后再进行一次遍历 poll ; timeout or 有数据才返回; 返回后有数据则将其从 内核态 copy 到 用户态。 } epoll VS select对于多路复用 I/O 所涉及的注册、通知和处理过程， 相较于 select ， epoll 将大部分工作放到了内核。由于其设计时专门考虑到了大量的 fd 处理场景，其效率要高很多，具体体现在: 少了 socket 句柄从 用户态 到 内核态的拷贝; 少了 select 每次对 fdset 的重新初始化; The most important: select 在内核层面还是轮询而非真正的异步，并且时机比 epoll 晚; select 是在 调用 select() 时才着手等待并记录异步事件; 而 epoll 先于 select ，即在 epoll_ctl() 添加 fd 时就已经开始等待并记录异步事件，这样调用 epoll_wait() 时马上就能返回已记录好的异步数据; 这是通过在内核中维护一个事件 list ，并在 epoll_ctl() 添加 fd 时，在内核中为每个 fd 注册 异步回调函数 (将 ep_poll_callback 挂到等待队列 wait_queue_head_t *whead) 的机制来实现的; [ eg: sys_epoll_ctl –&gt; ep_insert –&gt; sock_poll –&gt; tcp_poll –&gt; poll_wait –&gt; ep_ptable_queue_proc –&gt; init_waitqueue_func_entry(&amp;pwq-&gt;wait, ep_poll_callback) ] 当对应的 fd 有事件发生 (eg: socket 收到报文， sock_def_readable) 时，主动唤醒等待队列 (wake_up_interruptible(sk-&gt;sk_sleep) )，即调用等待队列上的回调函数，回调函数就将对应的 fd 添加到事件 list ，待 epoll_wait() 时直接从 list 取出即可; 可知，对于 epoll 进程来讲，事件获取的大部分工作其实是由系统 (对于 socket 而言收发包为软中断，而非用户进程) 在幕后完成的，进程只是纯粹的读取结果; 而 select 进程对事件的轮询，其工作都由 select 进程自己 (从用户态到内核态) 当场完成; 当被监视的 fd 数目非常大时，select 和 poll 系统调用完成操作需时 O(n) ，而 epoll 能在 O(1) 时间内完成; 显然， epoll 要快的多。 PS: libevent Linux - epoll，BSD - kqueue，Solaris - “/dev/poll” “类 select 模型将事件探测和事件响应夹杂在一起，一旦事件响应的执行体庞大，则对整个模型是灾难性的。幸运的是，有很多高效的事件驱动库可以屏蔽上述的困难，常见的事件驱动库有 libevent 库，还有作为 libevent 替代者的 libev 库。这些库会根据操作系统的特点选择最合适的事件探测接口，并且加入了信号 (signal) 等技术以支持异步响应，这使得这些库成为构建事件驱动模型的不二选择。”","tags":[{"name":"network","slug":"network","permalink":"http://walter-du.github.io/tags/network/"},{"name":"I/O","slug":"I-O","permalink":"http://walter-du.github.io/tags/I-O/"}]},{"title":"How 'sleep' happens","date":"2016-12-13T16:00:00.000Z","path":"2016/12/14/How_sleep_happens/","text":"sleep 的实现过程sleep –&gt; sys_nanosleep{ 为当前进程注册一个 timer 及超时回调函数 process_timeout; 将进程置为 TASK_INTERRUPTIBLE; 将 timer 挂到每 CPU 链 tvec_bases; schedule() 让出 CPU; 时钟软中断 TIMER_SOFTIRQ 函数 run_timer_softirq 检查 tvec_bases 是否有 timer 超时; 超时则回调 process_timeout 进而 wake_up_process 唤醒进程到 TASK_RUNNING,等待时间片调度。 }","tags":[{"name":"Linux","slug":"Linux","permalink":"http://walter-du.github.io/tags/Linux/"}]},{"title":"'Property' and 'getattr'","date":"2016-11-27T16:00:00.000Z","path":"2016/11/28/Property_AND_getattr/","text":"@property 只能针对单个属性;getattr 作用于该 class 的所有属性; 显然，应用场景就很不同了。 “The main downside to properties is that they aren’t reusable.”“Most of the time/in the general case, property is of no use unless you DO need to do some extra work when access the attribute.” Refer to: http://nbviewer.jupyter.org/urls/gist.github.com/ChrisBeaumont/5758381/raw/descriptor_writeup.ipynb","tags":[{"name":"Python","slug":"Python","permalink":"http://walter-du.github.io/tags/Python/"}]}]